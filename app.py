import io
import streamlit as st
import boto3
from PIL import Image, ImageDraw, ImageFont

# ğŸ” Streamlit secretsì—ì„œ AWS ìê²©ì¦ëª… ë¶ˆëŸ¬ì˜¤ê¸°
aws_key = st.secrets["AWS_ACCESS_KEY_ID"]
aws_secret = st.secrets["AWS_SECRET_ACCESS_KEY"]
region = "ap-northeast-2"  # ì„œìš¸ ë¦¬ì „

# â–¶ï¸ Rekognition í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = boto3.client(
    'rekognition',
    aws_access_key_id=aws_key,
    aws_secret_access_key=aws_secret,
    region_name=region
)

# ì‚¬ì´ë“œë°” ë©”ë‰´ ì„¤ì •
st.sidebar.title("ë©”ë‰´ ì„ íƒ")
app_mode = st.sidebar.selectbox("ê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”", ["ì–¼êµ´ ê°ì • ë¶„ì„", "ì–¼êµ´ ë¹„êµ"])

def draw_faces_with_info(image_bytes, face_details):
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    draw = ImageDraw.Draw(image)
    width, height = image.size
    
    try:
        font = ImageFont.truetype("arial.ttf", 20)
    except:
        font = ImageFont.load_default()
    
    for idx, face in enumerate(face_details):
        box = face['BoundingBox']
        left = int(box['Left'] * width)
        top = int(box['Top'] * height)
        box_width = int(box['Width'] * width)
        box_height = int(box['Height'] * height)
        
        box_colors = ["red", "blue", "green", "yellow", "purple"]
        box_color = box_colors[idx % len(box_colors)]
        
        draw.rectangle(
            [(left, top), (left + box_width, top + box_height)],
            outline=box_color, width=3
        )
        
        gender = face['Gender']['Value']
        age_range = face['AgeRange']
        emotions = face['Emotions']
        top_emotion = max(emotions, key=lambda x: x['Confidence'])
        
        info_text = (
            f"ì–¼êµ´ {idx+1}\n"
            f"ì„±ë³„: {gender}\n"
            f"ë‚˜ì´: {age_range['Low']}-{age_range['High']}\n"
            f"ê°ì •: {top_emotion['Type']}"
        )
        
        text_bg_height = 80
        draw.rectangle(
            [(left, top - text_bg_height), (left + 150, top)],
            fill="black"
        )
        draw.text(
            (left + 5, top - text_bg_height + 5),
            info_text,
            fill=box_color,
            font=font
        )
    
    return image

if app_mode == "ì–¼êµ´ ê°ì • ë¶„ì„":
    st.title("ğŸ§‘â€ğŸ”¬ ì–¼êµ´ ì¸ì‹ê¸° (Amazon Rekognition ê¸°ë°˜ ê°ì • ë¶„ì„)")
    
    uploaded_file = st.file_uploader("ì–¼êµ´ì´ ë³´ì´ëŠ” ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        image_bytes = uploaded_file.read()

        response = client.detect_faces(
            Image={'Bytes': image_bytes},
            Attributes=['ALL']
        )

        face_details = response['FaceDetails']

        if len(face_details) == 0:
            st.warning("ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.image(image_bytes, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€", use_container_width=True)
        else:
            annotated_image = draw_faces_with_info(image_bytes, face_details)
            
            col1, col2 = st.columns(2)
            with col1:
                st.image(image_bytes, caption="ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)
            with col2:
                st.image(annotated_image, caption="ì–¼êµ´ ë¶„ì„ ê²°ê³¼", use_container_width=True)

            st.subheader("ğŸ‘¤ ìƒì„¸ ì–¼êµ´ ë¶„ì„ ê²°ê³¼")
            
            for idx, face in enumerate(face_details):
                st.markdown(f"### ğŸŸ¢ ì–¼êµ´ {idx+1} ë¶„ì„ ê²°ê³¼")
                
                box_colors = ["red", "blue", "green", "yellow", "purple"]
                box_color = box_colors[idx % len(box_colors)]
                st.markdown(f"<hr style='border: 2px solid {box_color}'>", unsafe_allow_html=True)
                
                age_range = face['AgeRange']
                gender = face['Gender']
                emotions = face['Emotions']
                top_emotion = max(emotions, key=lambda x: x['Confidence'])
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì„±ë³„", f"{gender['Value']} ({gender['Confidence']:.1f}%)")
                with col2:
                    st.metric("ì¶”ì • ë‚˜ì´", f"{age_range['Low']}~{age_range['High']}ì„¸")
                with col3:
                    st.metric("ì£¼ìš” ê°ì •", f"{top_emotion['Type']} ({top_emotion['Confidence']:.1f}%)")
                
                st.write("**ê°ì • ë¶„ì„ ê²°ê³¼:**")
                emotions_sorted = sorted(emotions, key=lambda x: -x['Confidence'])
                for emotion in emotions_sorted:
                    st.progress(int(emotion['Confidence']), 
                              text=f"{emotion['Type']}: {emotion['Confidence']:.1f}%")
                
                with st.expander("ì¶”ê°€ ì–¼êµ´ ì†ì„± ë³´ê¸°"):
                    attrs = {
                        "Eyeglasses": "ì•ˆê²½ ì°©ìš©",
                        "Sunglasses": "ì„ ê¸€ë¼ìŠ¤ ì°©ìš©",
                        "Beard": "ìˆ˜ì—¼",
                        "Mustache": "ì½§ìˆ˜ì—¼",
                        "EyesOpen": "ëˆˆ ëœ¸",
                        "MouthOpen": "ì… ì—´ë¦¼",
                        "Smile": "ë¯¸ì†Œ"
                    }
                    
                    for attr, desc in attrs.items():
                        if attr in face:
                            value = face[attr]
                            st.write(f"- {desc}: {'ì˜ˆ' if value['Value'] else 'ì•„ë‹ˆì˜¤'} ({value['Confidence']:.1f}%)")
                
                st.write("")

elif app_mode == "ì–¼êµ´ ë¹„êµ":
    st.title("ğŸ§‘â€ğŸ¤â€ğŸ§‘ ì–¼êµ´ ë¹„êµê¸° (Amazon Rekognition)")

    st.subheader("ğŸ“· ë¹„êµí•  ë‘ ì¥ì˜ ì–¼êµ´ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
    col1, col2 = st.columns(2)
    with col1:
        image1 = st.file_uploader("ì´ë¯¸ì§€ 1", type=["jpg", "jpeg", "png"], key="img1")
    with col2:
        image2 = st.file_uploader("ì´ë¯¸ì§€ 2", type=["jpg", "jpeg", "png"], key="img2")

    if image1 and image2:
        image1_bytes = image1.read()
        image2_bytes = image2.read()

        try:
            response = client.compare_faces(
                SourceImage={'Bytes': image1_bytes},
                TargetImage={'Bytes': image2_bytes},
                SimilarityThreshold=50
            )

            st.subheader("ğŸ” ë¹„êµ ê²°ê³¼")
            col1, col2 = st.columns(2)
            with col1:
                st.image(image1_bytes, caption="ì´ë¯¸ì§€ 1", use_container_width=True)
            with col2:
                st.image(image2_bytes, caption="ì´ë¯¸ì§€ 2", use_container_width=True)

            face_matches = response['FaceMatches']
            if len(face_matches) == 0:
                st.warning("ë‘ ì‚¬ëŒì€ ë™ì¼ ì¸ë¬¼ë¡œ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                match = face_matches[0]
                similarity = match['Similarity']
                
                st.write(f"**ì–¼êµ´ ìœ ì‚¬ë„:** {similarity:.2f}%")
                st.progress(int(similarity), text=f"ìœ ì‚¬ë„ {similarity:.2f}%")
                
                if similarity > 95:
                    st.success("âœ… ê°™ì€ ì‚¬ëŒì¼ ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤ (95% ì´ìƒ)")
                elif similarity > 80:
                    st.info("ğŸŸ¢ ê°™ì€ ì‚¬ëŒì¼ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤ (80%~95%)")
                elif similarity > 60:
                    st.warning("ğŸŸ¡ ìœ ì‚¬í•˜ì§€ë§Œ ë‹¤ë¥¸ ì‚¬ëŒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (60%~80%)")
                else:
                    st.error("ğŸ”´ ë‹¤ë¥¸ ì‚¬ëŒì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤ (60% ë¯¸ë§Œ)")

            with st.expander("ê¸°ìˆ ì  ì„¸ë¶€ ì •ë³´ ë³´ê¸°"):
                st.json(response)

        except Exception as e:
            st.error(f"ì—ëŸ¬ ë°œìƒ: {str(e)}")
